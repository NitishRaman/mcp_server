# ğŸš€ MCP Server

A modular Python-based platform to **ingest**, **describe**, **query**, and **visualize** structured datasets using **LLMs**, **vector databases**, and an intuitive **Streamlit UI**.

---

## ğŸ“‹ Overview & Use Case

MCP Server is ideal for:

* ğŸ“Š Data analysts exploring unknown datasets
* ğŸ§  LLM-based schema summarization
* ğŸ§¾ Prompt-to-SQL generation with conversational context
* ğŸŒ Teams working with Supabase or local data pipelines

---

## ğŸ”§ Key Features

* ğŸ“¥ Upload & parse CSV, Excel, ZIP, JSON, XML, and SQLite
* ğŸ§  Generate column descriptions, PK/FK inference, and tags via LLM
* ğŸ” Vectorize schemas with `sentence-transformers` and ChromaDB
* ğŸ§¾ Translate prompts to SQL (with logs)
* ğŸ’¬ Multi-turn chat with LLM to explore database
* ğŸ“ˆ Build visual charts from structured data
* ğŸ›¢ï¸ Push SQLite tables to Supabase
* ğŸŒ Streamlit UI + FastAPI API backend

---

## ğŸ—‚ï¸ Project Structure

```
ğŸ“ mcp_server_project/
â”œâ”€â”€ ğŸ“ app/                         # Core modules
â”‚   â”œâ”€â”€ core/                      # Constants and config
â”‚   â”œâ”€â”€ chromadb_prompt_utils.py
â”‚   â”œâ”€â”€ chart_generator.py
â”‚   â”œâ”€â”€ data_ingestor.py
â”‚   â”œâ”€â”€ data_ingestor_server.py
â”‚   â”œâ”€â”€ llm_client.py
â”‚   â”œâ”€â”€ natural_sql_query.py
â”‚   â”œâ”€â”€ schema_describer.py
â”‚   â”œâ”€â”€ schema_diagram.py
â”‚   â”œâ”€â”€ schema_vectorizer.py
â”‚   â””â”€â”€ supabase_utils.py
â”‚
â”œâ”€â”€ ğŸ“ mcp_server/
â”‚   â””â”€â”€ files/                     # Generated files per dataset
â”‚       â””â”€â”€ chroma/                # Vector DB store
â”‚
â”œâ”€â”€ ğŸ“ sample_datasets/            # Sample datasets to test flow
â”œâ”€â”€ ğŸ“ pages/                      # Streamlit UI pages (modular)
â”‚   â”œâ”€â”€ 1 Upload & Preview.py
â”‚   â”œâ”€â”€ 2 Description & Schema Generator.py
â”‚   â”œâ”€â”€ 3 Prompt to SQL.py
â”‚   â”œâ”€â”€ 4 Chart Generator.py
â”‚   â”œâ”€â”€ 5 Supabase.py
â”‚   â””â”€â”€ 6 Interactive Prompt Chat.py
â”‚
â”œâ”€â”€ Home.py                       # Landing page
â”œâ”€â”€ app_server.py                 # FastAPI backend
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run.bat                       # One-click launcher
â”œâ”€â”€ mcp-documentation.pdf         # Full documentation
â”œâ”€â”€ mcp-presentation.pdf          # Project presentation deck
â””â”€â”€ README.md                     # This file
```

---

## âš™ï¸ Setup

### âœ… One-click (Windows)

```bash
run.bat
```

This will:

* Create `.venv`
* Install dependencies
* Launch ChromaDB, pull Ollama, start backend + UI

### ğŸ§ Manual (Linux/macOS)

```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
uvicorn app_server:app --reload
```

---

## ğŸ“Š Streamlit Modules

### 1. Upload & Preview

* `save_and_ingest_file()`
* Helpers: `read_csv_from_bytes()`, `read_zip()`, etc.

### 2. Description & Schema

* `describe_database()`
* Helpers: `llm_infer_keys_from_description()`, `vectorize_database()`

### 3. Prompt to SQL

* `generate_sql_from_prompt()`
* Helpers: `run_query_on_db()`, `log_successful_query()`

### 4. Chart Generator

* `plot_chart(df, chart_type, x_col, y_col)`

### 5. Supabase

* `handle_supabase_connection()`
* Helpers: `fetch_supabase_tables()`, `fetch_table_sample()`

### 6. Interactive Prompt Chat

* `generate_sql_from_prompt()`
* Helpers: `generate_sql_strict()`, `log_query()`

---

## ğŸ’¾ Output Directory (per dataset)

```
ğŸ“ files/my_dataset/
â”œâ”€â”€ my_dataset.db                  # SQLite version
â”œâ”€â”€ *.csv / *.json / *.xml         # Original input
â”œâ”€â”€ my_dataset_description.txt     # LLM-generated schema summary
â”œâ”€â”€ my_dataset_metadata.json       # PK, FK, tags, etc.
â”œâ”€â”€ query_log.txt                  # Prompt-to-SQL history
â”œâ”€â”€ interactive_query_log.txt      # Chat history
â”œâ”€â”€ my_dataset_supabase.png        # ER Diagram (optional)
```

---

## ğŸ” Vector Embedding (ChromaDB)

Uses `sentence-transformers` to embed column names, types, and summaries. Stored per dataset under collection `schema_<dataset>`.

âœ… Enables context-aware SQL, semantic search, and chat memory.

---

## ğŸ§ª Run & Test

```bash
streamlit run Home.py            # Run full UI
uvicorn app_server:app --reload  # Backend API only
```

---

## ğŸ“¦ Key Dependencies (`requirements.txt`)

### ğŸ”¹ Core

* `pandas`, `numpy`, `openpyxl`, `sqlparse`, `pyyaml`, `xmlschema`, `jsonschema`, `tqdm`, `jinja2`, `chardet`

### ğŸ”¹ Visualization

* `matplotlib`, `graphviz`, `eralchemy`

### ğŸ”¹ UI & Backend

* `streamlit>=1.30`, `fastapi`, `uvicorn`, `ipywidgets`, `ipython`, `notebook`

### ğŸ”¹ LLM + Vector DB

* `openai`, `ollama`, `gpt4all`, `chromadb>=0.5.0`, `sentence-transformers`, `torch`, `scikit-learn`

### ğŸ”¹ SQL / DB

* `sqlite-utils`, `psycopg2-binary`

### ğŸ”¹ Utilities

* `typing-extensions`

---

## â— Troubleshooting

| Issue                | Solution                              |
| -------------------- | ------------------------------------- |
| Port 8000 in use     | Kill existing app or change port      |
| Ollama pull fails    | Make sure Ollama CLI is installed     |
| ChromaDB won't start | Activate venv + ensure port open      |
| No module named xyz  | Run `pip install -r requirements.txt` |

---

## ğŸ› ï¸ Extending the Project

* Add new file readers in `data_ingestor.py`
* Swap models in `llm_client.py`
* Customize outputs (descriptions, diagrams, SQL prompts)

---

## ğŸ“š Documentation

* ğŸ“˜ Full Guide â†’ `mcp-documentation.pdf`
* ğŸ“Š Pitch Deck â†’ `mcp-presentation.pdf`

---
